# Prototype d'Assistant IA avec Ollama

Voici mon prototype d'assistant personnel intelligent conÃ§u pour fonctionner localement grÃ¢ce Ã  [Ollama](https://ollama.com/). Ce projet vise Ã  explorer les capacitÃ©s des modÃ¨les de langage locaux pour crÃ©er une expÃ©rience d'assistance personnalisÃ©e et Ã©volutive.

---

## Ã€ propos de ce projet

Ce prototype est la premiÃ¨re Ã©tape vers la crÃ©ation d'un assistant IA personnel. Cette premiÃ¨re Ã©tape comprend un prototype de chatbot qui peut activer des fonctions python (function calling), en mode stream afin d'avoir une interface plus fluide, et en mode think pour qu'il puisse prendre de meilleures dÃ©cisions sur la maniÃ¨re dont rÃ©pondre Ã  l'utilisateur.

L'objectif final est de construire un assistant qui apprend de maniÃ¨re autonome et s'intÃ¨gre de faÃ§on transparente dans le quotidien de l'utilisateur.

---

## Architecture du projet

Le projet est structurÃ© pour sÃ©parer la logique de l'assistant, les outils et les diffÃ©rents scripts de test. Voici une description dÃ©taillÃ©e de l'arborescence :

```
Local_Ollama_Assistant/
â”œâ”€â”€ sketch/
â”‚   â”œâ”€â”€ chatbot.py                 # Script principal du chatbot
â”‚   â””â”€â”€ functions/                 # Fonctions outils (Tool Calling)
â”‚       â”œâ”€â”€ calculette.py          # Outil de calcul mathÃ©matique
â”‚       â”œâ”€â”€ system.py              # Fonctions systÃ¨me (heure, date, etc.)
â”‚       â”œâ”€â”€ todo/                  # Gestion des tÃ¢ches
â”‚       â”‚   â”œâ”€â”€ todo_list_for_JARVIS.py
â”‚       â”‚   â””â”€â”€ tests/
â”‚       â”‚       â”œâ”€â”€ todo_list.py
â”‚       â”‚       â””â”€â”€ todo.json
â”‚       â””â”€â”€ user_settings/         # Gestion de la mÃ©moire utilisateur
â”‚           â””â”€â”€ user_short_memory.py
â”œâ”€â”€ tests/                         # Scripts de test
â”‚   â”œâ”€â”€ test_4_think.py
â”‚   â””â”€â”€ test_chat_continu_plus_appel_fonctions.py
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ README.md                      # Documentation du projet
â””â”€â”€ .gitignore
```

Cette organisation a pour but de rendre le projet modulaire et facile Ã  faire Ã©voluer. De nouvelles fonctionnalitÃ©s (connexion Ã  des APIs, recherche web, etc.) peuvent par exemple Ãªtre ajoutÃ©es comme de nouveaux modules dans le dossier `functions`.

---

## Comment l'utiliser

Le programme utilise Ollama, un logiciel permettant de tÃ©lÃ©charger des modÃ¨les d'IA open source en local et de les faire tourner, voir [mon cours sur Ollama](https://github.com/matteolavallee/Cours_Ollama) pour voir comment je m'y suis pris.

Pour utiliser simplement le chatbot, je conseille
qwen 3 (modÃ¨le qui peut utiliser le mode think).

Pour dÃ©sactiver le think, il suffit de retirer, commenter ou passer en false la ligne ci-dessous dans le fichier `chatbot.py` :
```python
think = True
```

Je conseille, sans think les modÃ¨les llama2 ou llama3.1.

Pour interagir avec, exÃ©cutez le fichier suivant :
```bash
python Local_Ollama_Assistant/sketch/chatbot.py
```
---

## FonctionnalitÃ©s actuelles

Le chatbot est en mode think afin qu'il puisse fournir les meilleures rÃ©ponses possibles et traiter de la meilleure maniÃ¨re les fonctions Ã  sa disposition. En effet, sans le mode think le LLM ne peut pas exÃ©cuter des instructions implicites (par exemple, mettre Ã  jour la todo list). Il faudrait sinon que l'utilisateur lui spÃ©cifie "Modifie tel paramÃ¨tre dans la todolist".

Ce prototype est dotÃ© de plusieurs "outils" (fonctions) que l'assistant peut dÃ©cider d'utiliser pour accomplir des tÃ¢ches. J'ai d'ailleurs fait en sorte d'ajouter des vÃ©rifications Ã  chaque utilisation de fonction pour Ãªtre sÃ»r que le LLM les exÃ©cute correctement.
*   **Gestion de la mÃ©moire utilisateur (`user_short_memory.py`) :** Permet Ã  l'assistant de se souvenir d'informations sur vous (nom, Ã¢ge, prÃ©fÃ©rences...) entre les conversations. Les donnÃ©es sont stockÃ©es dans `user_memory.json`.
*   **Gestion de liste de tÃ¢ches (`todo.py`) :** Une fonction simple pour ajouter, supprimer et consulter des Ã©lÃ©ments dans une liste de tÃ¢ches, permettant Ã  l'assistant de vous aider Ã  vous organiser.
*   **Fonctions systÃ¨me (`system.py`):** Donne Ã  l'assistant l'accÃ¨s Ã  des informations de base comme la date et l'heure actuelles. Il y a aussi un fichier `calculette.py` qui contient des exemples de fonctions de calculette de base. 

## Installation et Configuration

1.  **PrÃ©requis :**
    *   Assurez-vous d'avoir Python installÃ© sur votre machine.
    *   Installez et configurez Ollama pour faire tourner un modÃ¨le de langage localement (je recommande qwen3 pour l'utiliser en mode think) :
        * Installez Ollama depuis cette page : https://ollama.com/download
        * ExÃ©cutez les commandes ci-dessous :
        
        ```
        ollama pull qwen3
        ```
        * Si ollama ne tourne pas encore, exÃ©cuter cette commande :
        ```
        ollama serve
        ```
        Cette derniÃ¨re permet de faire tourner l'instance d'Ollama sur le port 11434 du pc. En tapant cette adresse : `http://localhost:11434/`, vous devriez voir "Ollama is running".
        * Il est maintenant prÃªt Ã  Ãªtre utilisÃ©.

2.  **Cloner le dÃ©pÃ´t :**
    ```bash
    git clone https://github.com/matteolavallee/Local_Ollama_Assistant.git
    ```

3.  **Installer les dÃ©pendances :**
    ```bash
    pip install -r Local_Ollama_Assistant/requirements.txt
    ```

4.  **Configuration de la mÃ©moire utilisateur :**
    Le systÃ¨me de mÃ©moire est conÃ§u pour s'initialiser tout seul. Lors du premier lancement de l'application, un fichier `user_memory.json` sera crÃ©Ã© dans le rÃ©pertoire `Local_Ollama_Assistant/sketch/functions/user_settings/` avec les valeurs par dÃ©faut suivantes :

    ```json
    {
        "Name": "",
        "Age": [
            ""
        ],
        "Birthday": "",
        "saved_memories": []
    }
    ```
    Il est donc conseillÃ© pour Ã©viter toute confusion de la part du LLM, de changer ces valeurs manuellement.
    Ce fichier est **essentiel** pour que l'assistant puisse stocker et rÃ©cupÃ©rer des informations sur vous.

## ğŸ“ Apprenez Ã  crÃ©er votre propre assistant !

Au cours du dÃ©veloppement de ce prototype, j'ai pris des notes dÃ©taillÃ©es et crÃ©Ã© un cours complet pour vous guider pas Ã  pas dans la crÃ©ation de votre propre assistant IA avec Ollama.

Si vous Ãªtes intÃ©ressÃ©, vous pouvez retrouver ce cours [**ici**](https://github.com/matteolavallee/Cours_Ollama).
