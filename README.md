# Prototype d'Assistant IA avec Ollama

Voici mon prototype d'assistant personnel intelligent con√ßu pour fonctionner localement gr√¢ce √† [Ollama](https://ollama.com/). Ce projet vise √† explorer les capacit√©s des mod√®les de langage locaux pour cr√©er une exp√©rience d'assistance personnalis√©e et √©volutive.

---

## √Ä propos de ce projet

Ce prototype est la premi√®re √©tape vers la cr√©ation d'un assistant IA personnel. Cette premi√®re √©tape comprend un prototype de chatbot qui peut activer des fonctions python (function calling), en mode stream afin d'avoir une interface plus fluide, et en mode think pour qu'il puisse prendre de meilleures d√©cisions sur la mani√®re dont r√©pondre √† l'utilisateur.

L'objectif final est de construire un assistant qui apprend de mani√®re autonome et s'int√®gre de fa√ßon transparente dans le quotidien de l'utilisateur.

---

## Architecture du projet

Le projet est structur√© pour s√©parer la logique de l'assistant, les outils et les diff√©rents scripts de test. Voici une description d√©taill√©e de l'arborescence :

*   `1-Prototype_Chatbot_Ollama/`:
    *   `sketch/`:
        *   `chatbot.py`: Le script principal et le plus abouti pour lancer l'assistant en ligne de commande. Il int√®gre la gestion du contexte, les outils et le mode "r√©flexion" (`think`).
    *   `functions/`: Regroupe tous les "outils" (fonctions Python) que l'assistant peut utiliser.
        *   `system.py`: Fonctions li√©es au syst√®me (date, heure, OS...).
        *   `todo/`: Module de gestion de la todo list.
        *   `user_settings/`: Module de gestion de la m√©moire de l'utilisateur (`user_short_memory.py`). Le fichier `user_memory.json` est g√©n√©r√© ici.
        *   `prompt_system.py`: Fichier contenant diff√©rentes versions des prompts syst√®me qui ont √©t√© test√©es.
    *   `tests/`: Contient des scripts de test et des versions alternatives du chatbot pour exp√©rimenter des fonctionnalit√©s sp√©cifiques.
    *   `requirements.txt`

Cette organisation a pour but de rendre le projet modulaire et facile √† faire √©voluer. De nouvelles fonctionnalit√©s (connexion √† des APIs, recherche web, etc.) peuvent par exemple √™tre ajout√©es comme de nouveaux modules dans le dossier `functions`.

---

## Comment l'utiliser

Le programme utilise Ollama, un logiciel permettant de t√©l√©charger des mod√®les d'IA open source en local et de les faire tourner, voir [mon cours sur Ollama](https://github.com/matteolavallee/Cours_Ollama) pour voir comment je m'y suis pris.

Pour utiliser simplement le chatbot, je conseille
qwen 3 (mod√®le qui peut utiliser le mode think).

Pour d√©sactiver le think, il suffit de retirer, commenter ou passer en false la ligne ci-dessous dans le fichier `chatbot.py` :
```python
think = True
```

Je conseille, sans think les mod√®les llama2 ou llama3.1.

Pour interagir avec, ex√©cutez le fichier suivant :
```bash
python 1-Prototype_Chatbot_Ollama/sketch/chatbot.py
```
---

## Fonctionnalit√©s actuelles

Le chatbot est en mode think afin qu'il puisse fournir les meilleures r√©ponses possibles et traiter de la meilleure mani√®re les fonctions √† sa disposition. En effet, sans le mode think le LLM ne peut pas ex√©cuter des instructions implicites (par exemple, mettre √† jour la todo list). Il faudrait sinon que l'utilisateur lui sp√©cifie "Modifie tel param√®tre dans la todolist".

Ce prototype est dot√© de plusieurs "outils" (fonctions) que l'assistant peut d√©cider d'utiliser pour accomplir des t√¢ches. J'ai d'ailleurs fait en sorte d'ajouter des v√©rifications √† chaque utilisation de fonction pour √™tre s√ªr que le LLM les ex√©cute correctement.
*   **Gestion de la m√©moire utilisateur (`user_short_memory.py`) :** Permet √† l'assistant de se souvenir d'informations sur vous (nom, √¢ge, pr√©f√©rences...) entre les conversations. Les donn√©es sont stock√©es dans `user_memory.json`.
*   **Gestion de liste de t√¢ches (`todo.py`) :** Une fonction simple pour ajouter, supprimer et consulter des √©l√©ments dans une liste de t√¢ches, permettant √† l'assistant de vous aider √† vous organiser.
*   **Fonctions syst√®me (`system.py`):** Donne √† l'assistant l'acc√®s √† des informations de base comme la date et l'heure actuelles. Il y a aussi un fichier `calculette.py` qui contient des exemples de fonctions de calculette de base. 

## Installation et Configuration

1.  **Pr√©requis :**
    *   Assurez-vous d'avoir Python install√© sur votre machine.
    *   Installez et configurez Ollama pour faire tourner un mod√®le de langage localement (je recommande qwen3 pour l'utiliser en mode think) :
        * Installez Ollama depuis cette page : https://ollama.com/download
        * Ex√©cutez les commandes ci-dessous :
        
        ```
        ollama pull qwen3
        ```
        * Si ollama ne tourne pas encore, ex√©cuter cette commande :
        ```
        ollama serve
        ```
        Cette derni√®re permet de faire tourner l'instance d'Ollama sur le port 11434 du pc. En tapant cette adresse : `http://localhost:11434/`, vous devriez voir "Ollama is running".
        * Il est maintenant pr√™t √† √™tre utilis√©.

2.  **Cloner le d√©p√¥t :**
    ```bash
    git clone https://github.com/matteolavallee/1-Prototype_Chatbot_Ollama.git
    ```

3.  **Installer les d√©pendances :**
    ```bash
    pip install -r 1-Prototype_Chatbot_Ollama/requirements.txt
    ```

4.  **Configuration de la m√©moire utilisateur :**
    Le syst√®me de m√©moire est con√ßu pour s'initialiser tout seul. Lors du premier lancement de l'application, un fichier `user_memory.json` sera cr√©√© dans le r√©pertoire `1-Prototype_Chatbot_Ollama/sketch/functions/user_settings/` avec les valeurs par d√©faut suivantes :

    ```json
    {
        "Name": "",
        "Age": [
            ""
        ],
        "Birthday": "",
        "saved_memories": []
    }
    ```
    Il est donc conseill√© pour √©viter toute confusion de la part du LLM, de changer ces valeurs manuellement.
    Ce fichier est **essentiel** pour que l'assistant puisse stocker et r√©cup√©rer des informations sur vous.

## üéì Apprenez √† cr√©er votre propre assistant !

Au cours du d√©veloppement de ce prototype, j'ai pris des notes d√©taill√©es et cr√©√© un cours complet pour vous guider pas √† pas dans la cr√©ation de votre propre assistant IA avec Ollama.

Si vous √™tes int√©ress√©, vous pouvez retrouver ce cours [**ici**](https://github.com/matteolavallee/Cours_Ollama).
